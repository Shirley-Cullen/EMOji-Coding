{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "collapsed_sections": [
        "Xu9nilyywJvT"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pickle\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import matplotlib.cm as cm\n",
        "from wordcloud import WordCloud\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import r2_score\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "kFVxxOsdyDFo"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\")"
      ],
      "metadata": {
        "id": "lkgOnfbfSzRm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJo7gbGLuH0J",
        "outputId": "866dc0b8-6a36-4c52-bb73-f9ac0a7ef11c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/My_Drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/My_Drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/My_Drive/MyDrive/2025 Spring/11777/Datasets\""
      ],
      "metadata": {
        "id": "3vv3EeR_cRlo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2d667f3-2066-41f4-8131-f5278356397c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/My_Drive/MyDrive/2025 Spring/11777/Datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Labels"
      ],
      "metadata": {
        "id": "SyYPNKK_VScg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_label = torch.from_numpy(np.load(\"label_train.npy\"))\n",
        "train_label = train_label[:, 0, 0]"
      ],
      "metadata": {
        "id": "Rl8LjUGlz9Mw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_label = torch.from_numpy(np.load(\"label_test.npy\"))\n",
        "test_label = test_label[:, 0, 0]"
      ],
      "metadata": {
        "id": "FNqfiy27PwvD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create DataLoader"
      ],
      "metadata": {
        "id": "L0LtvWai1rvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, embeddings, labels):\n",
        "        self.embeddings = torch.tensor(embeddings, dtype=torch.float32)  # Convert to Tensor\n",
        "        self.labels = torch.tensor(labels, dtype=torch.float32)  # Convert to Tensor\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.embeddings)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.embeddings[idx], self.labels[idx]  # Return (embedding, sentiment_label)"
      ],
      "metadata": {
        "id": "yPvA0pqdzzJQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM"
      ],
      "metadata": {
        "id": "i_PiFXmbw1U9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentLSTM(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim, dropout=0.2):\n",
        "        super(SentimentLSTM, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        lstm_out, _ = self.lstm(x)  # Output shape: (batch_size, seq_length, hidden_dim)\n",
        "        final_out = lstm_out[:, -1, :]  # Take last LSTM output\n",
        "        final_out = self.dropout(final_out)\n",
        "        return self.fc(final_out)  # Output sentiment intensity"
      ],
      "metadata": {
        "id": "bc0pR1LmyMGs"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, criterion, optimizer, num_epochs):\n",
        "    model.train()\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "        epoch_loss = 0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.float(), labels.float()\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs).squeeze()\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss / len(train_loader)}\")\n",
        "\n",
        "def predict(model, input_embedding, device):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        input_embedding = input_embedding.to(device).float()\n",
        "        sentiment_score = model(input_embedding).squeeze()\n",
        "    return sentiment_score.cpu()"
      ],
      "metadata": {
        "id": "6wIDdERLw82L"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation Metrics"
      ],
      "metadata": {
        "id": "Lus-5mgeTrsm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_mae(predictions, test_label):\n",
        "  l1_loss_fn = nn.L1Loss()\n",
        "  loss = l1_loss_fn(predictions, test_label)\n",
        "  return loss.item()"
      ],
      "metadata": {
        "id": "YGl8j2Wx3Gve"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_acc(predictions, test_label):\n",
        "  predicted_labels = (predictions >= 0).long()  # Convert to 0/1 classes\n",
        "  true_labels = (test_label >= 0).long()  # Convert true values to 0/1\n",
        "  accuracy = (predicted_labels == true_labels).float().mean().item()\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "xnPNCamo9YDP"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_mse(predictions, true_labels):\n",
        "  mse_loss = nn.MSELoss()\n",
        "  loss = mse_loss(predictions, true_labels)\n",
        "  print(f\"MSE Loss: {loss.item()}\")"
      ],
      "metadata": {
        "id": "qXrAbEjj9jZg"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_pearson_corr(predictions, true_labels):\n",
        "  predictions, true_labels = predictions.float(), true_labels.float()\n",
        "  # Compute mean values\n",
        "  pred_mean = predictions.mean()\n",
        "  true_mean = true_labels.mean()\n",
        "\n",
        "  # Compute Covariance\n",
        "  numerator = torch.sum((predictions - pred_mean) * (true_labels - true_mean))\n",
        "\n",
        "  # Compute Standard Deviation\n",
        "  denominator = torch.sqrt(torch.sum((predictions - pred_mean) ** 2)) * torch.sqrt(torch.sum((true_labels - true_mean) ** 2))\n",
        "\n",
        "  corr = (numerator / denominator).item()\n",
        "\n",
        "  return corr"
      ],
      "metadata": {
        "id": "7V44Fy0AAxp8"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_accuracy_7(predictions, true_labels):\n",
        "    batch_size = predictions.shape[0]\n",
        "\n",
        "    errors = torch.abs(predictions - true_labels.view(-1, 1))  # Shape: (batch_size, num_samples)\n",
        "\n",
        "    # Get indices of the 7 closest predictions\n",
        "    top7_indices = torch.topk(errors, k=7, dim=1, largest=False).indices\n",
        "\n",
        "    # Check if the ground truth value is among the closest 7 predictions\n",
        "    correct = torch.any(top7_indices == 0, dim=1).float()\n",
        "    return correct.mean().item()"
      ],
      "metadata": {
        "id": "CJniUC1OC1Lb"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Unimodal"
      ],
      "metadata": {
        "id": "dek0jkqGUl7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = \"text_embeddings_train.npy\"\n",
        "train = torch.from_numpy(np.load(train_data))\n",
        "test_data = \"text_embeddings_test.npy\"\n",
        "test = torch.from_numpy(np.load(test_data))\n",
        "train_dataset = SentimentDataset(train, train_label)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIunH69YUem9",
        "outputId": "80a04c5b-a6de-4f3d-c9a2-903130c90487"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-a32d8149105f>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.embeddings = torch.tensor(embeddings, dtype=torch.float32)  # Convert to Tensor\n",
            "<ipython-input-13-a32d8149105f>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.labels = torch.tensor(labels, dtype=torch.float32)  # Convert to Tensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = train.shape[-1]\n",
        "hidden_dim = 300\n",
        "num_layers = 2\n",
        "output_dim = 1\n",
        "batch_size = 32\n",
        "num_epochs = 10\n",
        "lr = 0.001\n",
        "model = SentimentLSTM(input_dim, hidden_dim, num_layers, output_dim)\n",
        "model.to(device)\n",
        "criterion = nn.L1Loss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "train_model(model, train_loader, criterion, optimizer, num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25Einof2Ph1p",
        "outputId": "df7adf07-67b9-42ed-b8ff-8786ae570717"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.7274075138825493\n",
            "Epoch 2/10, Loss: 0.6517192131735807\n",
            "Epoch 3/10, Loss: 0.6213554716040244\n",
            "Epoch 4/10, Loss: 0.5951123219530177\n",
            "Epoch 5/10, Loss: 0.5697418814652586\n",
            "Epoch 6/10, Loss: 0.5420108481279324\n",
            "Epoch 7/10, Loss: 0.5128574528222914\n",
            "Epoch 8/10, Loss: 0.4783081463346743\n",
            "Epoch 9/10, Loss: 0.44787338029031887\n",
            "Epoch 10/10, Loss: 0.41729232362688407\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation**"
      ],
      "metadata": {
        "id": "5hQQplurU5ZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = predict(model, test, device)\n",
        "mae = calculate_mae(predictions, test_label)\n",
        "print(f\"MAE: {mae}\")\n",
        "pc = calculate_pearson_corr(predictions, test_label)\n",
        "print(f\"Pearson Corr: {pc}\")\n",
        "r2 = r2_score(test_label.cpu().numpy(), predictions.cpu().numpy())\n",
        "print(f\"R2 Score: {r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwRSNUGoU0A1",
        "outputId": "27ef4f50-1764-493f-b28c-a828e4d531f5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 0.6220446825027466\n",
            "Pearson Corr: 0.6760468482971191\n",
            "R2 Score: 0.42650842666625977\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multimodal"
      ],
      "metadata": {
        "id": "f4UBc0Y4ULFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def concat_modality(src1, src2):\n",
        "  train1 = src1\n",
        "  train2 = src2\n",
        "  train1 = torch.from_numpy(np.load(train1))\n",
        "  train2 = torch.from_numpy(np.load(train2))\n",
        "\n",
        "  train1 = train1.permute(0, 2, 1) #(batch_size, embed_dim, seq_len)\n",
        "  train2 = train2.permute(0, 2, 1)\n",
        "\n",
        "  train1_pooled = F.adaptive_avg_pool1d(train1, output_size=5)\n",
        "  train2_pooled = F.adaptive_avg_pool1d(train2, output_size=5)\n",
        "\n",
        "  new_train = torch.cat((train1_pooled, train2_pooled), dim=1)\n",
        "  new_train = new_train.permute(0, 2, 1) #(batch_size, seq_len, embed_dim)\n",
        "  print(\"New data shape:\", new_train.shape)\n",
        "  return new_train\n"
      ],
      "metadata": {
        "id": "32nWkF1nRAtr"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_visual = \"visual_face_train.npy\"\n",
        "train_text = \"text_embeddings_train.npy\"\n",
        "new_train = concat_modality(train_visual, train_text)\n",
        "train_dataset = SentimentDataset(new_train, train_label)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQvi7vKSR6LE",
        "outputId": "a3161a46-a71f-4341-bc4a-8653b067e184"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New data shape: torch.Size([16327, 5, 335])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-a32d8149105f>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.embeddings = torch.tensor(embeddings, dtype=torch.float32)  # Convert to Tensor\n",
            "<ipython-input-13-a32d8149105f>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.labels = torch.tensor(labels, dtype=torch.float32)  # Convert to Tensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = new_train.shape[-1]\n",
        "hidden_dim = 100\n",
        "num_layers = 2\n",
        "output_dim = 1\n",
        "batch_size = 32\n",
        "num_epochs = 10\n",
        "lr = 0.01\n",
        "model = SentimentLSTM(input_dim, hidden_dim, num_layers, output_dim)\n",
        "model.to(device)\n",
        "criterion = nn.L1Loss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "train_model(model, train_loader, criterion, optimizer, num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BX1e4CSMOhZ6",
        "outputId": "85ff9b41-3fc6-4419-e006-aa8e92ea2cba"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1/10 [00:02<00:23,  2.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.7824766578739637\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:04<00:19,  2.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10, Loss: 0.7286703557417584\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [00:07<00:16,  2.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10, Loss: 0.7141564553731108\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [00:09<00:14,  2.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10, Loss: 0.6942280932765185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [00:11<00:11,  2.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10, Loss: 0.6871814873003913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [00:14<00:09,  2.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10, Loss: 0.6762212981449881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [00:16<00:07,  2.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10, Loss: 0.6688413876610027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [00:19<00:04,  2.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/10, Loss: 0.6629223397216685\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [00:21<00:02,  2.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10, Loss: 0.6581406690136561\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:24<00:00,  2.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10, Loss: 0.6573706014982175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation**"
      ],
      "metadata": {
        "id": "5x9PsXLjT3wL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_visual = \"visual_face_test.npy\"\n",
        "test_text = \"text_embeddings_test.npy\"\n",
        "new_test = concat_modality(test_visual, test_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQGzMlLlP9BA",
        "outputId": "c59c7103-c5b6-49e6-9347-38563c4491f4"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New data shape: torch.Size([4662, 5, 335])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = predict(model, new_test, device)\n",
        "mae = calculate_mae(predictions, test_label)\n",
        "print(f\"MAE: {mae}\")\n",
        "pc = calculate_pearson_corr(predictions, test_label)\n",
        "print(f\"Pearson Corr: {pc}\")\n",
        "r2 = r2_score(test_label.cpu().numpy(), predictions.cpu().numpy())\n",
        "print(f\"R2 Score: {r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwyvDZinOoxR",
        "outputId": "48834ff5-4095-4e1c-8c04-07dc35e90fe7"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 0.6804166436195374\n",
            "Pearson Corr: 0.5921444892883301\n",
            "R2 Score: 0.30067217350006104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Tensors(Optional)"
      ],
      "metadata": {
        "id": "Xu9nilyywJvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "objects = []\n",
        "with open('tensors.pkl', 'rb') as f:\n",
        "    while True:\n",
        "        try:\n",
        "            obj = pickle.load(f)\n",
        "            objects.append(obj)\n",
        "            break\n",
        "        except EOFError:\n",
        "            break\n",
        "train_all = objects[0][0][0]\n",
        "val_all = objects[0][0][1]\n",
        "test_all = objects[0][0][2]"
      ],
      "metadata": {
        "id": "mOe1VR-jxRd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('text_embeddings_val.npy', val_all['glove_vectors'])\n",
        "np.save('text_embeddings_train.npy', train_all['glove_vectors'])\n",
        "np.save('text_embeddings_test.npy', test_all['glove_vectors'])"
      ],
      "metadata": {
        "id": "BcRHCIg8YQMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('label_val.npy', val_all['All Labels'])\n",
        "np.save('label_train.npy', train_all['All Labels'])\n",
        "np.save('label_test.npy', test_all['All Labels'])"
      ],
      "metadata": {
        "id": "qLoeGef5xc2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('audios_embeddings_train.npy', train_all['COAVAREP'])\n",
        "np.save('audios_embeddings_val.npy', val_all['COAVAREP'])\n",
        "np.save('audios_embeddings_test.npy', test_all['COAVAREP'])"
      ],
      "metadata": {
        "id": "qHnIBrzQCLn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('visual_face_train.npy', train_all['FACET 4.2'])\n",
        "np.save('visual_face_val.npy', val_all['FACET 4.2'])\n",
        "np.save('visual_face_test.npy', test_all['FACET 4.2'])"
      ],
      "metadata": {
        "id": "FLFc3tRKL47A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('visual_op_train.npy', train_all['OpenFace_2.0'])\n",
        "np.save('visual_op_val.npy', val_all['OpenFace_2.0'])\n",
        "np.save('visual_op_test.npy', test_all['OpenFace_2.0'])"
      ],
      "metadata": {
        "id": "hOn2C5eQMAxF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}